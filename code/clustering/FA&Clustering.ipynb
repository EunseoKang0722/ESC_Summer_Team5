{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Analysis & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Hitter </center>\n",
    "<img src=\"https://www.ducksters.com/sports/baseball/hitter.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_hit_2016 = pd.read_csv('team_hitter_scaling_2016.csv',index_col=0)\n",
    "team_pit_2016 = pd.read_csv('team_pitcher_scaling_2016.csv',index_col=0)\n",
    "team_hit_2016 = pd.merge(team_hit_2016,team_pit_2016[['G_ID','WLS','TB_SC']], on=['G_ID','TB_SC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor Analysis(FA)는 잠재변수를 찾는 방식이다. 잠재변수에 의해 X변수들이 결정된다고 가정한다. 순서는 다음과 같다.\n",
    "\n",
    "1) **Choosing the Number of Factors**(Kaiser criterion & scree plot): <br>\n",
    "고유값에 근거하여 적절한 요인의 개수를 판단 <br>\n",
    "2) **Factor Analysis**: <br>\n",
    "factor analysis를 통하여 factor가 어느 변수와 high factor loadings을 갖는지 살펴야함.\n",
    "\n",
    "[참조](https://www.datacamp.com/community/tutorials/introduction-factor-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Number of Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'team_hit_2016' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15a468b7819e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'RUN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P_HRA_RT'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AVG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SLG'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'IsoP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OBP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'OPS'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RC'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'XR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wOBA'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BABIP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteam_hit_2016\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Target y는 WLS로 설정한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'team_hit_2016' is not defined"
     ]
    }
   ],
   "source": [
    "features = ['RUN','P_HRA_RT','AVG','SLG','IsoP','OBP','OPS','RC','XR','wOBA','BABIP']\n",
    "df = team_hit_2016.loc[:,features]\n",
    "# Target y는 WLS로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "fa = FactorAnalyzer()\n",
    "fa.analyze(df, 10, rotation='varimax')\n",
    "ev, v = fa.get_eigenvalues()\n",
    "# ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiser Criterion에 의하여 고유값이 1보다 큰 경우만 factor로 취급한다. <br>\n",
    "따라서 이 경우에는 factor의 갯수를 3개로 두자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(1, df.shape[1]+1),ev)\n",
    "plt.plot(range(1,df.shape[1]+1),ev)\n",
    "plt.grid(axis='y')\n",
    "plt.show() #Factor가 3개일때만 1을 넘는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer()\n",
    "fa.analyze(df, 3, rotation=\"varimax\")\n",
    "#각 loading 값들이 최대한 서로 다르게 하기위해 Varimax rotation 실행.#fa.loadings\n",
    "#fa.loadings\n",
    "# fa.loadgins=L이며 L은 factor간 선형결합의 weight를 의미함. L 추정 중요\n",
    "hit_loadings = fa.loadings.copy()\n",
    "hit_loadings = hit_loadings.apply(lambda x: np.where(x==max(x)), axis=1)\n",
    "hit_loadings = hit_loadings.apply(lambda x: int(sum(x)))\n",
    "hit_loadings = hit_loadings.to_dict()\n",
    "hit_fac = {n:[k for k in hit_loadings.keys() if hit_loadings[k] == n] for n in set(hit_loadings.values())}\n",
    "for i in range(len(hit_fac.keys())):\n",
    "    hit_fac['Factor'+str(i+1)] = hit_fac.pop(i)\n",
    "hit_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1(타율,출루계열)** : AVG, OBP, wOBA, BABIP <br>\n",
    "AVG(타율), OBP(출루율), wOBA(가중 출루율), BABIP\n",
    "\n",
    "**F2(득점계열)** : RUN, P_HRA_RT, RC, XR <br>\n",
    "RUN(득점), P_HHA_RT(득점권타율), RC(득점기여도), XR(득점 공헌도)\n",
    "\n",
    "**F3(장타율계열)** : SLG, IsoP, OPS <br>\n",
    "SLG(장타율), IsoP(순장타율), ops(출루율+장타율)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.get_factor_variance()\n",
    "# Total 86% cumulative Variance explained by the 3 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "fa = FactorAnalysis(n_components=3)\n",
    "X_fa = fa.fit_transform(X) # FA를 위해 E(X-mu)=0를 만들어주려고 mu를 빼주는듯?\n",
    "df_fa =pd.DataFrame(data=X_fa, columns=['hit_f1','hit_f2','hit_f3'])\n",
    "names = ['WLS','G_ID','T_ID','TB_SC']\n",
    "for name in names:\n",
    "    df_fa[name] = team_hit_2016[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_fa, hue='WLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaching for an optimal k (the elbow point)\n",
    "sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(df_fa[['hit_f1','hit_f2','hit_f3']])\n",
    "    sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5).fit(df_fa[['hit_f1','hit_f2','hit_f3']])\n",
    "df_fa['cluster_hit'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_fa['cluster_hit'],df_fa['T_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df_fa['hit_f1'],df_fa['hit_f2'],df_fa['hit_f3'],c=df_fa['cluster_hit'])\n",
    "ax.set_xlabel('F1')\n",
    "ax.set_ylabel('F2')\n",
    "ax.set_zlabel('F3',rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Pitcher </center>\n",
    "<img src=\"http://sportsgroundproduction.blob.core.windows.net/cms/14732/newsarticles/63254_wo.jpg\" width=\"220\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_pit_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['R','ER','P_WHIP_RT','K/9','BB/9','K/BB','OAVG','OOBP','OSLG','OOPS','WHIP','BABIP','DICE',\n",
    "                                               'ERA','RA9','FIP','kFIP','HR/9','H/9']\n",
    "df = team_pit_2016.loc[:,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer()\n",
    "fa.analyze(df, 10, rotation='varimax')\n",
    "ev, v = fa.get_eigenvalues()\n",
    "# ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(1, df.shape[1]+1), ev)\n",
    "plt.plot(range(1, df.shape[1]+1),ev)\n",
    "plt.grid(axis='y')\n",
    "plt.show # 4개 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer()\n",
    "fa.analyze(df, 4, rotation='varimax')\n",
    "#fa.loadings\n",
    "pit_loadings = fa.loadings.copy()\n",
    "pit_loadings = pit_loadings.apply(lambda x: np.where(x==max(x)), axis=1)\n",
    "pit_loadings = pit_loadings.apply(lambda x: int(sum(x)))\n",
    "pit_loadings = pit_loadings.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_fac = {n:[k for k in pit_loadings.keys() if pit_loadings[k] == n] for n in set(pit_loadings.values())}\n",
    "for i in range(len(pit_fac.keys())):\n",
    "    pit_fac['Factor'+str(i+1)] = pit_fac.pop(i)\n",
    "pit_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.get_factor_variance()\n",
    "# Total 87% cumulative Variance explained by the 4 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "fa = FactorAnalysis(n_components=4)\n",
    "X_fa = fa.fit_transform(X) # FA를 위해 E(X-mu)=0를 만들어주려고 mu를 빼주는듯?\n",
    "df2_fa =pd.DataFrame(data=X_fa, columns=['pit_f1','pit_f2','pit_f3','pit_f4'])\n",
    "for name in names:\n",
    "    df2_fa[name] = team_pit_2016[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaching for an optimal k (the elbow point)\n",
    "sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(df2_fa[['pit_f1','pit_f2','pit_f3','pit_f4']])\n",
    "    sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3).fit(df2_fa[['pit_f1','pit_f2','pit_f3','pit_f4']])\n",
    "df2_fa['cluster_pit'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df2_fa, hue='cluster_pit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fa = pd.merge(df_fa,df2_fa, on=['G_ID','T_ID','TB_SC','WLS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3).fit(final_fa[['hit_f1','hit_f2','hit_f3','pit_f1','pit_f2','pit_f3','pit_f4']])\n",
    "final_fa['cluster_play'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_play = pd.crosstab(final_fa['cluster_play'],final_fa['T_ID'])\n",
    "cross_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_hit = pd.crosstab(final_fa['cluster_hit'],final_fa['T_ID'])\n",
    "cross_pit = pd.crosstab(final_fa['cluster_pit'],final_fa['T_ID'])\n",
    "\n",
    "def cluster_max(crosstable,name):\n",
    "    cluster_team = crosstable.apply(lambda x: np.where(x==max(x)))\n",
    "    cluster_team = cluster_team.apply(lambda x: int(sum(x)))\n",
    "    cluster_team = pd.DataFrame(cluster_team)\n",
    "    cluster_team = cluster_team.reset_index()\n",
    "    cluster_team.columns = ['T_ID',name]\n",
    "    return(cluster_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.merge(final_fa, cluster_max(cross_hit,'cluster_team_hit'),on='T_ID')\n",
    "cluster = pd.merge(cluster, cluster_max(cross_pit,'cluster_team_pit'),on='T_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = cluster[['G_ID','T_ID','TB_SC','WLS','cluster_team_hit','cluster_team_pit','hit_f1','hit_f2','hit_f3','pit_f1','pit_f2','pit_f3','pit_f4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.to_csv('cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cluster.copy()\n",
    "data = data.sort_values(['G_ID']).reset_index(drop=True)\n",
    "data['T'] = None\n",
    "data['B'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    data.iloc[i, 13] = data.iloc[i, 0][8:10]\n",
    "    data.iloc[i, 14] = data.iloc[i, 0][10:12]\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['T'], prefix='T', drop_first=True)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['B'], prefix='B', drop_first=True)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['TB_SC'], drop_first=True)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['cluster_team_hit'], prefix='HIT', drop_first=True)], axis=1)\n",
    "data = pd.concat([data, pd.get_dummies(data['cluster_team_pit'], prefix='PIT', drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['G_ID', 'T_ID', 'TB_SC', 'cluster_team_hit', 'cluster_team_pit', 'T', 'B',\n",
    "                 'hit_f1','hit_f2','hit_f3','pit_f1','pit_f2','pit_f3','pit_f4'], axis=1)\n",
    "data.head()\n",
    "\n",
    "X_train = data.iloc[:1250, 1:]\n",
    "y_train = data.iloc[:1250, 0]\n",
    "X_test = data.iloc[1250:, 1:]\n",
    "y_test = data.iloc[1250:, 0]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('예측 정확도:', round(sum(y_pred == y_test)/len(y_pred == y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in range(3,8):\n",
    "    for k2 in range(3,8):\n",
    "        kmeans = KMeans(n_clusters=k1).fit(df_fa[['hit_f1','hit_f2','hit_f3']])\n",
    "        df_fa['cluster_hit'] = kmeans.labels_\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k2).fit(df2_fa[['pit_f1','pit_f2','pit_f3','pit_f4']])\n",
    "        df2_fa['cluster_pit'] = kmeans.labels_\n",
    "\n",
    "        final_fa = pd.merge(df_fa,df2_fa, on=['G_ID','T_ID','TB_SC','WLS'])\n",
    "        \n",
    "        cross_hit = pd.crosstab(final_fa['cluster_hit'],final_fa['T_ID'])\n",
    "        cross_pit = pd.crosstab(final_fa['cluster_pit'],final_fa['T_ID'])\n",
    "        cluster = pd.merge(final_fa, cluster_max(cross_hit,'cluster_team_hit'),on='T_ID')\n",
    "        cluster = pd.merge(cluster, cluster_max(cross_pit,'cluster_team_pit'),on='T_ID')\n",
    "\n",
    "        data = cluster[['G_ID','T_ID','TB_SC','WLS','cluster_team_hit','cluster_team_pit','hit_f1','hit_f2','hit_f3','pit_f1','pit_f2','pit_f3','pit_f4']]\n",
    "        data = data.sort_values(['G_ID']).reset_index(drop=True)\n",
    "        data['T'] = None\n",
    "        data['B'] = None\n",
    "        for i in range(data.shape[0]):\n",
    "            data.iloc[i, 13] = data.iloc[i, 0][8:10]\n",
    "            data.iloc[i, 14] = data.iloc[i, 0][10:12]\n",
    "\n",
    "        data = pd.concat([data, pd.get_dummies(data['T'], prefix='T', drop_first=True)], axis=1)\n",
    "        data = pd.concat([data, pd.get_dummies(data['B'], prefix='B', drop_first=True)], axis=1)\n",
    "        data = pd.concat([data, pd.get_dummies(data['TB_SC'], drop_first=True)], axis=1)\n",
    "        data = pd.concat([data, pd.get_dummies(data['cluster_team_hit'], prefix='HIT', drop_first=True)], axis=1)\n",
    "        data = pd.concat([data, pd.get_dummies(data['cluster_team_pit'], prefix='PIT', drop_first=True)], axis=1)\n",
    "\n",
    "        data = data.drop(['G_ID', 'T_ID', 'TB_SC', 'cluster_team_hit', 'cluster_team_pit', 'T', 'B',\n",
    "                 'hit_f1','hit_f2','hit_f3','pit_f1','pit_f2','pit_f3','pit_f4'], axis=1)\n",
    "\n",
    "        X_train = data.iloc[:1250, 1:]\n",
    "        y_train = data.iloc[:1250, 0]\n",
    "        X_test = data.iloc[1250:, 1:]\n",
    "        y_test = data.iloc[1250:, 0]\n",
    "\n",
    "        model = RandomForestClassifier(random_state=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        print('예측 정확도:',k1,k2,round(sum(y_pred == y_test)/len(y_pred == y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_hit.apply(lambda x: np.where(x==max(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
