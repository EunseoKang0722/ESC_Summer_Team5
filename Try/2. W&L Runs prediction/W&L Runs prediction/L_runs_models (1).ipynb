{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('L_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'CG_CK', 'WLS', 'HOLD', 'INN2',\n",
       "       'BF', 'PA', 'AB', 'HIT', 'H1', 'H2', 'H3', 'HR', 'SB', 'CS', 'SH', 'SF',\n",
       "       'BB', 'IB', 'HP', 'KK', 'GD', 'WP', 'BK', 'Pitcher_ERR', 'R', 'ER',\n",
       "       'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'K/BB', 'OOPS', 'WHIP',\n",
       "       'BABIP', 'kFIP', 'HEADER_NO_1', 'HEADER_NO_2', 'TB_SC_T', 'Hitter_ERR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.loc[-data['G_ID'].str.contains('2020')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**\n",
    "test set을 다르게 정해서 각각의 스코어 살피고 가장 좋은 스코어를 내는 test set 방식을 채택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. train/test; 19년도 끝에서 188경기만 test로\n",
    "전체 데이터중 16년~19년 초->train set/ 19년말 188경기-> test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:-188]\n",
    "valid = data.iloc[-188:]\n",
    "train=train.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid=valid.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.drop(['R'],axis=1)\n",
    "X_test= valid.drop(['R'],axis=1)\n",
    "y_train=train[['R']]\n",
    "y_test= valid[['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800531863494186\n",
      "0.8643697316631911\n"
     ]
    }
   ],
   "source": [
    "pred= rf.predict(X_test)\n",
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리드서치...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.86\n",
      "Best parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train, y_train)\n",
    "                score=forest.score(X_test, y_test)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. '16~'19 매년 끝 188개를 test로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_ID</th>\n",
       "      <th>GDAY_DS</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>VS_T_ID</th>\n",
       "      <th>CG_CK</th>\n",
       "      <th>WLS</th>\n",
       "      <th>HOLD</th>\n",
       "      <th>INN2</th>\n",
       "      <th>BF</th>\n",
       "      <th>PA</th>\n",
       "      <th>...</th>\n",
       "      <th>CB_WHIP_RT</th>\n",
       "      <th>K/BB</th>\n",
       "      <th>OOPS</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>kFIP</th>\n",
       "      <th>HEADER_NO_1</th>\n",
       "      <th>HEADER_NO_2</th>\n",
       "      <th>TB_SC_T</th>\n",
       "      <th>Hitter_ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160401HHLG0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>LG</td>\n",
       "      <td>HH</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>184</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.652618</td>\n",
       "      <td>0.295302</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.100408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160401HHLG0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>HH</td>\n",
       "      <td>LG</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>196</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>0.250296</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.186543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160401HTNC0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NC</td>\n",
       "      <td>HT</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>143</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.727554</td>\n",
       "      <td>0.268456</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.214354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160401HTNC0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>HT</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>147</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.395973</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160401KTSK0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>SK</td>\n",
       "      <td>KT</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>151</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.853175</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.350408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            G_ID   GDAY_DS T_ID VS_T_ID  CG_CK WLS  HOLD  INN2   BF        PA  \\\n",
       "0  20160401HHLG0  20160401   LG      HH      0   W     0    36  184  0.729167   \n",
       "1  20160401HHLG0  20160401   HH      LG      0   L     0    34  196  0.625000   \n",
       "2  20160401HTNC0  20160401   NC      HT      0   W     0    27  143  0.437500   \n",
       "3  20160401HTNC0  20160401   HT      NC      0   L     0    24  147  0.395833   \n",
       "4  20160401KTSK0  20160401   SK      KT      0   L     0    27  151  0.520833   \n",
       "\n",
       "   ...  CB_WHIP_RT      K/BB      OOPS      WHIP     BABIP      kFIP  \\\n",
       "0  ...    0.200000  0.238095  0.652618  0.295302  0.361111  0.100408   \n",
       "1  ...    0.062500  0.196429  0.615942  0.250296  0.266667  0.186543   \n",
       "2  ...    0.178571  0.238095  0.727554  0.268456  0.304348  0.214354   \n",
       "3  ...    0.156250  0.128571  0.966667  0.395973  0.368421  0.365714   \n",
       "4  ...    0.187500  0.125000  0.853175  0.375839  0.321429  0.350408   \n",
       "\n",
       "   HEADER_NO_1  HEADER_NO_2  TB_SC_T  Hitter_ERR  \n",
       "0            0            0        0         0.0  \n",
       "1            0            0        1         0.4  \n",
       "2            0            0        0         0.2  \n",
       "3            0            0        1         0.0  \n",
       "4            0            0        0         0.2  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 =data.loc[data['G_ID'].str.contains('2016')]\n",
    "train2016 = data2016.iloc[:-188]\n",
    "valid2016 = data2016.iloc[-188:]\n",
    "\n",
    "data2017 =data.loc[data['G_ID'].str.contains('2017')]\n",
    "train2017 = data2017.iloc[:-188]\n",
    "valid2017 = data2017.iloc[-188:]\n",
    "\n",
    "data2018 =data.loc[data['G_ID'].str.contains('2018')]\n",
    "train2018 = data2018.iloc[:-188]\n",
    "valid2018 = data2018.iloc[-188:]\n",
    "\n",
    "data2019 =data.loc[data['G_ID'].str.contains('2019')]\n",
    "train2019 = data2019.iloc[:-188]\n",
    "valid2019 = data2019.iloc[-188:]\n",
    "\n",
    "train=pd.concat([train2016,train2017,train2018, train2019],axis=0)\n",
    "valid=pd.concat([valid2016,valid2017, valid2018, valid2019],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid=valid.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.drop(['R'],axis=1)\n",
    "X_test= valid.drop(['R'],axis=1)\n",
    "y_train=train[['R']]\n",
    "y_test= valid[['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797112161234798\n",
      "0.8755977248000496\n"
     ]
    }
   ],
   "source": [
    "pred= rf.predict(X_test)\n",
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.87\n",
      "Best parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train, y_train)\n",
    "                score=forest.score(X_test, y_test)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 16~19년, 연도별로 따로 끝에서 188개 test set으로 만들고, 연도별로 각각 돌려보기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 =data.loc[data['G_ID'].str.contains('2016')]\n",
    "train2016 = data2016.iloc[:-188]\n",
    "valid2016 = data2016.iloc[-188:]\n",
    "\n",
    "data2017 =data.loc[data['G_ID'].str.contains('2017')]\n",
    "train2017 = data2017.iloc[:-188]\n",
    "valid2017 = data2017.iloc[-188:]\n",
    "\n",
    "data2018 =data.loc[data['G_ID'].str.contains('2018')]\n",
    "train2018 = data2018.iloc[:-188]\n",
    "valid2018 = data2018.iloc[-188:]\n",
    "\n",
    "data2019 =data.loc[data['G_ID'].str.contains('2019')]\n",
    "train2019 = data2019.iloc[:-188]\n",
    "valid2019 = data2019.iloc[-188:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2016=train2016.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid2016=valid2016.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "\n",
    "train2017=train2017.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid2017=valid2017.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "\n",
    "train2018=train2018.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid2018=valid2018.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "\n",
    "train2019=train2019.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid2019=valid2019.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2016=train.drop(['R'],axis=1);X_test2016= valid.drop(['R'],axis=1)\n",
    "y_train2016=train[['R']];y_test2016= valid[['R']]\n",
    "X_train2017=train.drop(['R'],axis=1);X_test2017= valid.drop(['R'],axis=1)\n",
    "y_train2017=train[['R']];y_test2017= valid[['R']]\n",
    "X_train2018=train.drop(['R'],axis=1);X_test2018= valid.drop(['R'],axis=1)\n",
    "y_train2018=train[['R']];y_test2018= valid[['R']]\n",
    "X_train2019=train.drop(['R'],axis=1);X_test2019= valid.drop(['R'],axis=1)\n",
    "y_train2019=train[['R']];y_test2019= valid[['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.87\n",
      "Best parameters: {'n_estimators': 150, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train2016, y_train2016)\n",
    "                score=forest.score(X_test2016, y_test2016)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.87\n",
      "Best parameters: {'n_estimators': 250, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train2017, y_train2017)\n",
    "                score=forest.score(X_test2017, y_test2017)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.87\n",
      "Best parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train2018, y_train2018)\n",
    "                score=forest.score(X_test2018, y_test2018)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.87\n",
      "Best parameters: {'n_estimators': 250, 'max_depth': None, 'min_samples_split': 0.01, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100,150,200,250]:\n",
    "    for max_depth in [None,6,9,12]:\n",
    "        for min_samples_split in [0.01, 0.05, 0.1]:\n",
    "            for max_features in ['auto', 'sqrt']:\n",
    "                forest= RandomForestRegressor(n_estimators=n_estimator,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split= min_samples_split,\n",
    "                                             max_features=max_features)\n",
    "                forest.fit(X_train2019, y_train2019)\n",
    "                score=forest.score(X_test2019, y_test2019)\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                        'min_samples_split' : min_samples_split,\n",
    "                                        'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생각보다 스코어 차이가 크지 않다, \n",
    "\n",
    "2)번 방식 선택!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 =data.loc[data['G_ID'].str.contains('2016')]\n",
    "train2016 = data2016.iloc[:-188]\n",
    "valid2016 = data2016.iloc[-188:]\n",
    "\n",
    "data2017 =data.loc[data['G_ID'].str.contains('2017')]\n",
    "train2017 = data2017.iloc[:-188]\n",
    "valid2017 = data2017.iloc[-188:]\n",
    "\n",
    "data2018 =data.loc[data['G_ID'].str.contains('2018')]\n",
    "train2018 = data2018.iloc[:-188]\n",
    "valid2018 = data2018.iloc[-188:]\n",
    "\n",
    "data2019 =data.loc[data['G_ID'].str.contains('2019')]\n",
    "train2019 = data2019.iloc[:-188]\n",
    "valid2019 = data2019.iloc[-188:]\n",
    "\n",
    "train=pd.concat([train2016,train2017,train2018, train2019],axis=0)\n",
    "valid=pd.concat([valid2016,valid2017, valid2018, valid2019],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)\n",
    "valid=valid.drop(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'WLS','ER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.drop(['R'],axis=1)\n",
    "X_test= valid.drop(['R'],axis=1)\n",
    "y_train=train[['R']]\n",
    "y_test= valid[['R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:39:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=4)\n",
    "xgb.fit(X_train,y_train)\n",
    "xgb_pred=xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2213eb75c88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.plot_importance(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9620902675766665"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8949259891915778"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.naver.com/PostView.nhn?blogId=gustn3964&logNo=221431714122\n",
    " min_child_weight (클수록 모델이 더 보수적) /\n",
    " max_depth / \n",
    " gamma (클수록 더 보수적) 는 반드시 조정\n",
    " \n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.90\n",
      "Best parameters: {'n_estimators': 400, 'max_depth': 4, 'min_samples_split': 0.1, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100, 200, 400, 600]:\n",
    "    for learning_rate in [0.01, 0.05, 0.1, 0.15, 0.2]:\n",
    "        for gamma in [0.5, 1, 1.5, 2, 5]:\n",
    "            for max_depth in [1,4,6,9]:\n",
    "                for min_child_weight in [0,1,3,5]:\n",
    "                    xgb= XGBRegressor(n_estimators=n_estimator,\n",
    "                                      learning_rate=learning_rate,           \n",
    "                                      gamma= gamma,\n",
    "                                      max_depth=max_depth,\n",
    "                                      min_child_weight=min_child_weight,objective ='reg:squarederror')\n",
    "                    xgb.fit(X_train, y_train)\n",
    "                    score=xgb.score(X_test, y_test)\n",
    "                \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                            'min_samples_split' : min_samples_split,\n",
    "                                            'max_features':max_features}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기부터는 무시하고 뒷부분부터 보시면 됩니다~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = lgb.Dataset(X_train, label = y_train) \n",
    "test_ds = lgb.Dataset(X_test, label = y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.01, \n",
    "          'max_depth': 16, \n",
    "          'boosting': 'gbdt', \n",
    "          'objective': 'regression', \n",
    "          'metric': 'mse', \n",
    "          'is_training_metric': True, \n",
    "          'num_leaves': 144, \n",
    "          'feature_fraction': 0.9, \n",
    "          'bagging_fraction': 0.7, \n",
    "          'bagging_freq': 5, \n",
    "          'seed':2018}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.23387\n",
      "[200]\tvalid_0's l2: 1.72677\n",
      "[300]\tvalid_0's l2: 1.43917\n",
      "[400]\tvalid_0's l2: 1.36614\n",
      "[500]\tvalid_0's l2: 1.34367\n",
      "[600]\tvalid_0's l2: 1.3318\n",
      "[700]\tvalid_0's l2: 1.33442\n",
      "Early stopping, best iteration is:\n",
      "[667]\tvalid_0's l2: 1.32986\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "predict_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3298583099311398\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, predict_test) #score가 잘 안구해져서 mse로 구했음\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://greatjoy.tistory.com/72 하이퍼파라미터 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88349\n",
      "[300]\tvalid_0's l2: 1.51936\n",
      "[400]\tvalid_0's l2: 1.40401\n",
      "[500]\tvalid_0's l2: 1.36715\n",
      "[600]\tvalid_0's l2: 1.34676\n",
      "[700]\tvalid_0's l2: 1.33441\n",
      "[800]\tvalid_0's l2: 1.32363\n",
      "[900]\tvalid_0's l2: 1.31656\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.70521\n",
      "[200]\tvalid_0's l2: 2.04738\n",
      "[300]\tvalid_0's l2: 1.6355\n",
      "[400]\tvalid_0's l2: 1.50333\n",
      "[500]\tvalid_0's l2: 1.4434\n",
      "[600]\tvalid_0's l2: 1.40682\n",
      "[700]\tvalid_0's l2: 1.38556\n",
      "[800]\tvalid_0's l2: 1.36863\n",
      "[900]\tvalid_0's l2: 1.35659\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48057\n",
      "[200]\tvalid_0's l2: 1.89263\n",
      "[300]\tvalid_0's l2: 1.52739\n",
      "[400]\tvalid_0's l2: 1.41823\n",
      "[500]\tvalid_0's l2: 1.38239\n",
      "[600]\tvalid_0's l2: 1.36372\n",
      "[700]\tvalid_0's l2: 1.34801\n",
      "[800]\tvalid_0's l2: 1.33404\n",
      "[900]\tvalid_0's l2: 1.32914\n",
      "[1000]\tvalid_0's l2: 1.32184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l2: 1.32181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88416\n",
      "[300]\tvalid_0's l2: 1.51626\n",
      "[400]\tvalid_0's l2: 1.40092\n",
      "[500]\tvalid_0's l2: 1.35953\n",
      "[600]\tvalid_0's l2: 1.33973\n",
      "[700]\tvalid_0's l2: 1.32602\n",
      "[800]\tvalid_0's l2: 1.31471\n",
      "[900]\tvalid_0's l2: 1.30703\n",
      "[1000]\tvalid_0's l2: 1.3031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l2: 1.30265\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.78589\n",
      "[600]\tvalid_0's l2: 3.58245\n",
      "[700]\tvalid_0's l2: 3.04823\n",
      "[800]\tvalid_0's l2: 2.85671\n",
      "[900]\tvalid_0's l2: 2.4568\n",
      "[1000]\tvalid_0's l2: 2.32734\n",
      "[100]\tvalid_0's l2: 10.9567\n",
      "[200]\tvalid_0's l2: 10.4344\n",
      "[300]\tvalid_0's l2: 7.39873\n",
      "[400]\tvalid_0's l2: 5.35251\n",
      "[500]\tvalid_0's l2: 4.02541\n",
      "[600]\tvalid_0's l2: 3.81431\n",
      "[700]\tvalid_0's l2: 3.26289\n",
      "[800]\tvalid_0's l2: 3.05283\n",
      "[900]\tvalid_0's l2: 2.63508\n",
      "[1000]\tvalid_0's l2: 2.48356\n",
      "[100]\tvalid_0's l2: 10.7334\n",
      "[200]\tvalid_0's l2: 10.1882\n",
      "[300]\tvalid_0's l2: 7.12262\n",
      "[400]\tvalid_0's l2: 5.08076\n",
      "[500]\tvalid_0's l2: 3.78667\n",
      "[600]\tvalid_0's l2: 3.58864\n",
      "[700]\tvalid_0's l2: 3.05146\n",
      "[800]\tvalid_0's l2: 2.85888\n",
      "[900]\tvalid_0's l2: 2.46237\n",
      "[1000]\tvalid_0's l2: 2.32266\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.7854\n",
      "[600]\tvalid_0's l2: 3.58576\n",
      "[700]\tvalid_0's l2: 3.05256\n",
      "[800]\tvalid_0's l2: 2.85842\n",
      "[900]\tvalid_0's l2: 2.46296\n",
      "[1000]\tvalid_0's l2: 2.32802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37551\n",
      "[200]\tvalid_0's l2: 1.317\n",
      "[300]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's l2: 1.31142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.44059\n",
      "[200]\tvalid_0's l2: 1.34372\n",
      "[300]\tvalid_0's l2: 1.3152\n",
      "[400]\tvalid_0's l2: 1.30731\n",
      "[500]\tvalid_0's l2: 1.30778\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's l2: 1.30291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.38926\n",
      "[200]\tvalid_0's l2: 1.32827\n",
      "[300]\tvalid_0's l2: 1.32641\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l2: 1.32116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37498\n",
      "[200]\tvalid_0's l2: 1.32804\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's l2: 1.32539\n",
      "[100]\tvalid_0's l2: 3.21138\n",
      "[200]\tvalid_0's l2: 1.99541\n",
      "[300]\tvalid_0's l2: 1.56389\n",
      "[400]\tvalid_0's l2: 1.39472\n",
      "[500]\tvalid_0's l2: 1.36755\n",
      "[600]\tvalid_0's l2: 1.41346\n",
      "[700]\tvalid_0's l2: 1.36486\n",
      "[800]\tvalid_0's l2: 1.36994\n",
      "[900]\tvalid_0's l2: 1.34485\n",
      "[1000]\tvalid_0's l2: 1.33889\n",
      "[100]\tvalid_0's l2: 3.4052\n",
      "[200]\tvalid_0's l2: 2.13587\n",
      "[300]\tvalid_0's l2: 1.63624\n",
      "[400]\tvalid_0's l2: 1.43485\n",
      "[500]\tvalid_0's l2: 1.37265\n",
      "[600]\tvalid_0's l2: 1.40606\n",
      "[700]\tvalid_0's l2: 1.34415\n",
      "[800]\tvalid_0's l2: 1.34603\n",
      "[900]\tvalid_0's l2: 1.30944\n",
      "[1000]\tvalid_0's l2: 1.30931\n",
      "[100]\tvalid_0's l2: 3.20083\n",
      "[200]\tvalid_0's l2: 2.0043\n",
      "[300]\tvalid_0's l2: 1.57112\n",
      "[400]\tvalid_0's l2: 1.39321\n",
      "[500]\tvalid_0's l2: 1.3563\n",
      "[600]\tvalid_0's l2: 1.40199\n",
      "[700]\tvalid_0's l2: 1.35569\n",
      "[800]\tvalid_0's l2: 1.35716\n",
      "[900]\tvalid_0's l2: 1.33887\n",
      "[1000]\tvalid_0's l2: 1.33847\n",
      "[100]\tvalid_0's l2: 3.2239\n",
      "[200]\tvalid_0's l2: 1.99248\n",
      "[300]\tvalid_0's l2: 1.57271\n",
      "[400]\tvalid_0's l2: 1.40819\n",
      "[500]\tvalid_0's l2: 1.3598\n",
      "[600]\tvalid_0's l2: 1.40445\n",
      "[700]\tvalid_0's l2: 1.36029\n",
      "[800]\tvalid_0's l2: 1.36129\n",
      "[900]\tvalid_0's l2: 1.3336\n",
      "[1000]\tvalid_0's l2: 1.32884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.3148\n",
      "[200]\tvalid_0's l2: 1.32605\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l2: 1.31107\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.35359\n",
      "[200]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's l2: 1.31779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34653\n",
      "[200]\tvalid_0's l2: 1.34904\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's l2: 1.33654\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34371\n",
      "[200]\tvalid_0's l2: 1.3526\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l2: 1.33746\n",
      "[100]\tvalid_0's l2: 1.84553\n",
      "[200]\tvalid_0's l2: 1.4235\n",
      "[300]\tvalid_0's l2: 1.34399\n",
      "[400]\tvalid_0's l2: 1.30451\n",
      "[500]\tvalid_0's l2: 1.31448\n",
      "[600]\tvalid_0's l2: 1.33447\n",
      "[700]\tvalid_0's l2: 1.31151\n",
      "[800]\tvalid_0's l2: 1.31962\n",
      "[900]\tvalid_0's l2: 1.31809\n",
      "[1000]\tvalid_0's l2: 1.32095\n",
      "[100]\tvalid_0's l2: 1.93214\n",
      "[200]\tvalid_0's l2: 1.46742\n",
      "[300]\tvalid_0's l2: 1.34737\n",
      "[400]\tvalid_0's l2: 1.28177\n",
      "[500]\tvalid_0's l2: 1.26905\n",
      "[600]\tvalid_0's l2: 1.29063\n",
      "[700]\tvalid_0's l2: 1.28379\n",
      "[800]\tvalid_0's l2: 1.28981\n",
      "[900]\tvalid_0's l2: 1.30482\n",
      "[1000]\tvalid_0's l2: 1.2963\n",
      "[100]\tvalid_0's l2: 1.83251\n",
      "[200]\tvalid_0's l2: 1.41877\n",
      "[300]\tvalid_0's l2: 1.33363\n",
      "[400]\tvalid_0's l2: 1.29744\n",
      "[500]\tvalid_0's l2: 1.29923\n",
      "[600]\tvalid_0's l2: 1.3181\n",
      "[700]\tvalid_0's l2: 1.28962\n",
      "[800]\tvalid_0's l2: 1.29677\n",
      "[900]\tvalid_0's l2: 1.29807\n",
      "[1000]\tvalid_0's l2: 1.30856\n",
      "[100]\tvalid_0's l2: 1.82291\n",
      "[200]\tvalid_0's l2: 1.43169\n",
      "[300]\tvalid_0's l2: 1.36347\n",
      "[400]\tvalid_0's l2: 1.32182\n",
      "[500]\tvalid_0's l2: 1.33207\n",
      "[600]\tvalid_0's l2: 1.3449\n",
      "[700]\tvalid_0's l2: 1.32037\n",
      "[800]\tvalid_0's l2: 1.33315\n",
      "[900]\tvalid_0's l2: 1.32149\n",
      "[1000]\tvalid_0's l2: 1.32327\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.40447\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 1.37575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.33538\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 1.33091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.41037\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's l2: 1.39167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.39207\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 1.35761\n",
      "[100]\tvalid_0's l2: 1.36686\n",
      "[200]\tvalid_0's l2: 1.33058\n",
      "[300]\tvalid_0's l2: 1.34368\n",
      "[400]\tvalid_0's l2: 1.33633\n",
      "[500]\tvalid_0's l2: 1.34706\n",
      "[600]\tvalid_0's l2: 1.33534\n",
      "[700]\tvalid_0's l2: 1.33249\n",
      "[800]\tvalid_0's l2: 1.34187\n",
      "[900]\tvalid_0's l2: 1.34363\n",
      "[1000]\tvalid_0's l2: 1.33625\n",
      "[100]\tvalid_0's l2: 1.38996\n",
      "[200]\tvalid_0's l2: 1.29407\n",
      "[300]\tvalid_0's l2: 1.26492\n",
      "[400]\tvalid_0's l2: 1.26353\n",
      "[500]\tvalid_0's l2: 1.26019\n",
      "[600]\tvalid_0's l2: 1.27848\n",
      "[700]\tvalid_0's l2: 1.27535\n",
      "[800]\tvalid_0's l2: 1.27991\n",
      "[900]\tvalid_0's l2: 1.28139\n",
      "[1000]\tvalid_0's l2: 1.28744\n",
      "[100]\tvalid_0's l2: 1.41847\n",
      "[200]\tvalid_0's l2: 1.34025\n",
      "[300]\tvalid_0's l2: 1.33943\n",
      "[400]\tvalid_0's l2: 1.33802\n",
      "[500]\tvalid_0's l2: 1.34587\n",
      "[600]\tvalid_0's l2: 1.34428\n",
      "[700]\tvalid_0's l2: 1.35235\n",
      "[800]\tvalid_0's l2: 1.35616\n",
      "[900]\tvalid_0's l2: 1.36728\n",
      "[1000]\tvalid_0's l2: 1.36915\n",
      "[100]\tvalid_0's l2: 1.41503\n",
      "[200]\tvalid_0's l2: 1.33698\n",
      "[300]\tvalid_0's l2: 1.3575\n",
      "[400]\tvalid_0's l2: 1.33318\n",
      "[500]\tvalid_0's l2: 1.3294\n",
      "[600]\tvalid_0's l2: 1.32733\n",
      "[700]\tvalid_0's l2: 1.33495\n",
      "[800]\tvalid_0's l2: 1.3543\n",
      "[900]\tvalid_0's l2: 1.35982\n",
      "[1000]\tvalid_0's l2: 1.36933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88349\n",
      "[300]\tvalid_0's l2: 1.51936\n",
      "[400]\tvalid_0's l2: 1.40401\n",
      "[500]\tvalid_0's l2: 1.36715\n",
      "[600]\tvalid_0's l2: 1.34676\n",
      "[700]\tvalid_0's l2: 1.33441\n",
      "[800]\tvalid_0's l2: 1.32363\n",
      "[900]\tvalid_0's l2: 1.31656\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.70521\n",
      "[200]\tvalid_0's l2: 2.04738\n",
      "[300]\tvalid_0's l2: 1.6355\n",
      "[400]\tvalid_0's l2: 1.50333\n",
      "[500]\tvalid_0's l2: 1.4434\n",
      "[600]\tvalid_0's l2: 1.40682\n",
      "[700]\tvalid_0's l2: 1.38556\n",
      "[800]\tvalid_0's l2: 1.36863\n",
      "[900]\tvalid_0's l2: 1.35659\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48057\n",
      "[200]\tvalid_0's l2: 1.89263\n",
      "[300]\tvalid_0's l2: 1.52739\n",
      "[400]\tvalid_0's l2: 1.41823\n",
      "[500]\tvalid_0's l2: 1.38239\n",
      "[600]\tvalid_0's l2: 1.36372\n",
      "[700]\tvalid_0's l2: 1.34801\n",
      "[800]\tvalid_0's l2: 1.33404\n",
      "[900]\tvalid_0's l2: 1.32914\n",
      "[1000]\tvalid_0's l2: 1.32184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l2: 1.32181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88416\n",
      "[300]\tvalid_0's l2: 1.51626\n",
      "[400]\tvalid_0's l2: 1.40092\n",
      "[500]\tvalid_0's l2: 1.35953\n",
      "[600]\tvalid_0's l2: 1.33973\n",
      "[700]\tvalid_0's l2: 1.32602\n",
      "[800]\tvalid_0's l2: 1.31471\n",
      "[900]\tvalid_0's l2: 1.30703\n",
      "[1000]\tvalid_0's l2: 1.3031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l2: 1.30265\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.78589\n",
      "[600]\tvalid_0's l2: 3.58245\n",
      "[700]\tvalid_0's l2: 3.04823\n",
      "[800]\tvalid_0's l2: 2.85671\n",
      "[900]\tvalid_0's l2: 2.4568\n",
      "[1000]\tvalid_0's l2: 2.32734\n",
      "[100]\tvalid_0's l2: 10.9567\n",
      "[200]\tvalid_0's l2: 10.4344\n",
      "[300]\tvalid_0's l2: 7.39873\n",
      "[400]\tvalid_0's l2: 5.35251\n",
      "[500]\tvalid_0's l2: 4.02541\n",
      "[600]\tvalid_0's l2: 3.81431\n",
      "[700]\tvalid_0's l2: 3.26289\n",
      "[800]\tvalid_0's l2: 3.05283\n",
      "[900]\tvalid_0's l2: 2.63508\n",
      "[1000]\tvalid_0's l2: 2.48356\n",
      "[100]\tvalid_0's l2: 10.7334\n",
      "[200]\tvalid_0's l2: 10.1882\n",
      "[300]\tvalid_0's l2: 7.12262\n",
      "[400]\tvalid_0's l2: 5.08076\n",
      "[500]\tvalid_0's l2: 3.78667\n",
      "[600]\tvalid_0's l2: 3.58864\n",
      "[700]\tvalid_0's l2: 3.05146\n",
      "[800]\tvalid_0's l2: 2.85888\n",
      "[900]\tvalid_0's l2: 2.46237\n",
      "[1000]\tvalid_0's l2: 2.32266\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.7854\n",
      "[600]\tvalid_0's l2: 3.58576\n",
      "[700]\tvalid_0's l2: 3.05256\n",
      "[800]\tvalid_0's l2: 2.85842\n",
      "[900]\tvalid_0's l2: 2.46296\n",
      "[1000]\tvalid_0's l2: 2.32802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37551\n",
      "[200]\tvalid_0's l2: 1.317\n",
      "[300]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's l2: 1.31142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.44059\n",
      "[200]\tvalid_0's l2: 1.34372\n",
      "[300]\tvalid_0's l2: 1.3152\n",
      "[400]\tvalid_0's l2: 1.30731\n",
      "[500]\tvalid_0's l2: 1.30778\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's l2: 1.30291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.38926\n",
      "[200]\tvalid_0's l2: 1.32827\n",
      "[300]\tvalid_0's l2: 1.32641\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l2: 1.32116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37498\n",
      "[200]\tvalid_0's l2: 1.32804\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's l2: 1.32539\n",
      "[100]\tvalid_0's l2: 3.21138\n",
      "[200]\tvalid_0's l2: 1.99541\n",
      "[300]\tvalid_0's l2: 1.56389\n",
      "[400]\tvalid_0's l2: 1.39472\n",
      "[500]\tvalid_0's l2: 1.36755\n",
      "[600]\tvalid_0's l2: 1.41346\n",
      "[700]\tvalid_0's l2: 1.36486\n",
      "[800]\tvalid_0's l2: 1.36994\n",
      "[900]\tvalid_0's l2: 1.34485\n",
      "[1000]\tvalid_0's l2: 1.33889\n",
      "[100]\tvalid_0's l2: 3.4052\n",
      "[200]\tvalid_0's l2: 2.13587\n",
      "[300]\tvalid_0's l2: 1.63624\n",
      "[400]\tvalid_0's l2: 1.43485\n",
      "[500]\tvalid_0's l2: 1.37265\n",
      "[600]\tvalid_0's l2: 1.40606\n",
      "[700]\tvalid_0's l2: 1.34415\n",
      "[800]\tvalid_0's l2: 1.34603\n",
      "[900]\tvalid_0's l2: 1.30944\n",
      "[1000]\tvalid_0's l2: 1.30931\n",
      "[100]\tvalid_0's l2: 3.20083\n",
      "[200]\tvalid_0's l2: 2.0043\n",
      "[300]\tvalid_0's l2: 1.57112\n",
      "[400]\tvalid_0's l2: 1.39321\n",
      "[500]\tvalid_0's l2: 1.3563\n",
      "[600]\tvalid_0's l2: 1.40199\n",
      "[700]\tvalid_0's l2: 1.35569\n",
      "[800]\tvalid_0's l2: 1.35716\n",
      "[900]\tvalid_0's l2: 1.33887\n",
      "[1000]\tvalid_0's l2: 1.33847\n",
      "[100]\tvalid_0's l2: 3.2239\n",
      "[200]\tvalid_0's l2: 1.99248\n",
      "[300]\tvalid_0's l2: 1.57271\n",
      "[400]\tvalid_0's l2: 1.40819\n",
      "[500]\tvalid_0's l2: 1.3598\n",
      "[600]\tvalid_0's l2: 1.40445\n",
      "[700]\tvalid_0's l2: 1.36029\n",
      "[800]\tvalid_0's l2: 1.36129\n",
      "[900]\tvalid_0's l2: 1.3336\n",
      "[1000]\tvalid_0's l2: 1.32884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.3148\n",
      "[200]\tvalid_0's l2: 1.32605\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l2: 1.31107\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.35359\n",
      "[200]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's l2: 1.31779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34653\n",
      "[200]\tvalid_0's l2: 1.34904\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's l2: 1.33654\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34371\n",
      "[200]\tvalid_0's l2: 1.3526\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l2: 1.33746\n",
      "[100]\tvalid_0's l2: 1.84553\n",
      "[200]\tvalid_0's l2: 1.4235\n",
      "[300]\tvalid_0's l2: 1.34399\n",
      "[400]\tvalid_0's l2: 1.30451\n",
      "[500]\tvalid_0's l2: 1.31448\n",
      "[600]\tvalid_0's l2: 1.33447\n",
      "[700]\tvalid_0's l2: 1.31151\n",
      "[800]\tvalid_0's l2: 1.31962\n",
      "[900]\tvalid_0's l2: 1.31809\n",
      "[1000]\tvalid_0's l2: 1.32095\n",
      "[100]\tvalid_0's l2: 1.93214\n",
      "[200]\tvalid_0's l2: 1.46742\n",
      "[300]\tvalid_0's l2: 1.34737\n",
      "[400]\tvalid_0's l2: 1.28177\n",
      "[500]\tvalid_0's l2: 1.26905\n",
      "[600]\tvalid_0's l2: 1.29063\n",
      "[700]\tvalid_0's l2: 1.28379\n",
      "[800]\tvalid_0's l2: 1.28981\n",
      "[900]\tvalid_0's l2: 1.30482\n",
      "[1000]\tvalid_0's l2: 1.2963\n",
      "[100]\tvalid_0's l2: 1.83251\n",
      "[200]\tvalid_0's l2: 1.41877\n",
      "[300]\tvalid_0's l2: 1.33363\n",
      "[400]\tvalid_0's l2: 1.29744\n",
      "[500]\tvalid_0's l2: 1.29923\n",
      "[600]\tvalid_0's l2: 1.3181\n",
      "[700]\tvalid_0's l2: 1.28962\n",
      "[800]\tvalid_0's l2: 1.29677\n",
      "[900]\tvalid_0's l2: 1.29807\n",
      "[1000]\tvalid_0's l2: 1.30856\n",
      "[100]\tvalid_0's l2: 1.82291\n",
      "[200]\tvalid_0's l2: 1.43169\n",
      "[300]\tvalid_0's l2: 1.36347\n",
      "[400]\tvalid_0's l2: 1.32182\n",
      "[500]\tvalid_0's l2: 1.33207\n",
      "[600]\tvalid_0's l2: 1.3449\n",
      "[700]\tvalid_0's l2: 1.32037\n",
      "[800]\tvalid_0's l2: 1.33315\n",
      "[900]\tvalid_0's l2: 1.32149\n",
      "[1000]\tvalid_0's l2: 1.32327\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.40447\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 1.37575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.33538\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 1.33091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.41037\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's l2: 1.39167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.39207\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 1.35761\n",
      "[100]\tvalid_0's l2: 1.36686\n",
      "[200]\tvalid_0's l2: 1.33058\n",
      "[300]\tvalid_0's l2: 1.34368\n",
      "[400]\tvalid_0's l2: 1.33633\n",
      "[500]\tvalid_0's l2: 1.34706\n",
      "[600]\tvalid_0's l2: 1.33534\n",
      "[700]\tvalid_0's l2: 1.33249\n",
      "[800]\tvalid_0's l2: 1.34187\n",
      "[900]\tvalid_0's l2: 1.34363\n",
      "[1000]\tvalid_0's l2: 1.33625\n",
      "[100]\tvalid_0's l2: 1.38996\n",
      "[200]\tvalid_0's l2: 1.29407\n",
      "[300]\tvalid_0's l2: 1.26492\n",
      "[400]\tvalid_0's l2: 1.26353\n",
      "[500]\tvalid_0's l2: 1.26019\n",
      "[600]\tvalid_0's l2: 1.27848\n",
      "[700]\tvalid_0's l2: 1.27535\n",
      "[800]\tvalid_0's l2: 1.27991\n",
      "[900]\tvalid_0's l2: 1.28139\n",
      "[1000]\tvalid_0's l2: 1.28744\n",
      "[100]\tvalid_0's l2: 1.41847\n",
      "[200]\tvalid_0's l2: 1.34025\n",
      "[300]\tvalid_0's l2: 1.33943\n",
      "[400]\tvalid_0's l2: 1.33802\n",
      "[500]\tvalid_0's l2: 1.34587\n",
      "[600]\tvalid_0's l2: 1.34428\n",
      "[700]\tvalid_0's l2: 1.35235\n",
      "[800]\tvalid_0's l2: 1.35616\n",
      "[900]\tvalid_0's l2: 1.36728\n",
      "[1000]\tvalid_0's l2: 1.36915\n",
      "[100]\tvalid_0's l2: 1.41503\n",
      "[200]\tvalid_0's l2: 1.33698\n",
      "[300]\tvalid_0's l2: 1.3575\n",
      "[400]\tvalid_0's l2: 1.33318\n",
      "[500]\tvalid_0's l2: 1.3294\n",
      "[600]\tvalid_0's l2: 1.32733\n",
      "[700]\tvalid_0's l2: 1.33495\n",
      "[800]\tvalid_0's l2: 1.3543\n",
      "[900]\tvalid_0's l2: 1.35982\n",
      "[1000]\tvalid_0's l2: 1.36933\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88349\n",
      "[300]\tvalid_0's l2: 1.51936\n",
      "[400]\tvalid_0's l2: 1.40401\n",
      "[500]\tvalid_0's l2: 1.36715\n",
      "[600]\tvalid_0's l2: 1.34676\n",
      "[700]\tvalid_0's l2: 1.33441\n",
      "[800]\tvalid_0's l2: 1.32363\n",
      "[900]\tvalid_0's l2: 1.31656\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.31097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.70521\n",
      "[200]\tvalid_0's l2: 2.04738\n",
      "[300]\tvalid_0's l2: 1.6355\n",
      "[400]\tvalid_0's l2: 1.50333\n",
      "[500]\tvalid_0's l2: 1.4434\n",
      "[600]\tvalid_0's l2: 1.40682\n",
      "[700]\tvalid_0's l2: 1.38556\n",
      "[800]\tvalid_0's l2: 1.36863\n",
      "[900]\tvalid_0's l2: 1.35659\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l2: 1.34761\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48057\n",
      "[200]\tvalid_0's l2: 1.89263\n",
      "[300]\tvalid_0's l2: 1.52739\n",
      "[400]\tvalid_0's l2: 1.41823\n",
      "[500]\tvalid_0's l2: 1.38239\n",
      "[600]\tvalid_0's l2: 1.36372\n",
      "[700]\tvalid_0's l2: 1.34801\n",
      "[800]\tvalid_0's l2: 1.33404\n",
      "[900]\tvalid_0's l2: 1.32914\n",
      "[1000]\tvalid_0's l2: 1.32184\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l2: 1.32181\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "[200]\tvalid_0's l2: 1.88416\n",
      "[300]\tvalid_0's l2: 1.51626\n",
      "[400]\tvalid_0's l2: 1.40092\n",
      "[500]\tvalid_0's l2: 1.35953\n",
      "[600]\tvalid_0's l2: 1.33973\n",
      "[700]\tvalid_0's l2: 1.32602\n",
      "[800]\tvalid_0's l2: 1.31471\n",
      "[900]\tvalid_0's l2: 1.30703\n",
      "[1000]\tvalid_0's l2: 1.3031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's l2: 1.30265\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.78589\n",
      "[600]\tvalid_0's l2: 3.58245\n",
      "[700]\tvalid_0's l2: 3.04823\n",
      "[800]\tvalid_0's l2: 2.85671\n",
      "[900]\tvalid_0's l2: 2.4568\n",
      "[1000]\tvalid_0's l2: 2.32734\n",
      "[100]\tvalid_0's l2: 10.9567\n",
      "[200]\tvalid_0's l2: 10.4344\n",
      "[300]\tvalid_0's l2: 7.39873\n",
      "[400]\tvalid_0's l2: 5.35251\n",
      "[500]\tvalid_0's l2: 4.02541\n",
      "[600]\tvalid_0's l2: 3.81431\n",
      "[700]\tvalid_0's l2: 3.26289\n",
      "[800]\tvalid_0's l2: 3.05283\n",
      "[900]\tvalid_0's l2: 2.63508\n",
      "[1000]\tvalid_0's l2: 2.48356\n",
      "[100]\tvalid_0's l2: 10.7334\n",
      "[200]\tvalid_0's l2: 10.1882\n",
      "[300]\tvalid_0's l2: 7.12262\n",
      "[400]\tvalid_0's l2: 5.08076\n",
      "[500]\tvalid_0's l2: 3.78667\n",
      "[600]\tvalid_0's l2: 3.58864\n",
      "[700]\tvalid_0's l2: 3.05146\n",
      "[800]\tvalid_0's l2: 2.85888\n",
      "[900]\tvalid_0's l2: 2.46237\n",
      "[1000]\tvalid_0's l2: 2.32266\n",
      "[100]\tvalid_0's l2: 10.7453\n",
      "[200]\tvalid_0's l2: 10.1784\n",
      "[300]\tvalid_0's l2: 7.11506\n",
      "[400]\tvalid_0's l2: 5.07677\n",
      "[500]\tvalid_0's l2: 3.7854\n",
      "[600]\tvalid_0's l2: 3.58576\n",
      "[700]\tvalid_0's l2: 3.05256\n",
      "[800]\tvalid_0's l2: 2.85842\n",
      "[900]\tvalid_0's l2: 2.46296\n",
      "[1000]\tvalid_0's l2: 2.32802\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37551\n",
      "[200]\tvalid_0's l2: 1.317\n",
      "[300]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's l2: 1.31142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.44059\n",
      "[200]\tvalid_0's l2: 1.34372\n",
      "[300]\tvalid_0's l2: 1.3152\n",
      "[400]\tvalid_0's l2: 1.30731\n",
      "[500]\tvalid_0's l2: 1.30778\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's l2: 1.30291\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.38926\n",
      "[200]\tvalid_0's l2: 1.32827\n",
      "[300]\tvalid_0's l2: 1.32641\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l2: 1.32116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.37498\n",
      "[200]\tvalid_0's l2: 1.32804\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's l2: 1.32539\n",
      "[100]\tvalid_0's l2: 3.21138\n",
      "[200]\tvalid_0's l2: 1.99541\n",
      "[300]\tvalid_0's l2: 1.56389\n",
      "[400]\tvalid_0's l2: 1.39472\n",
      "[500]\tvalid_0's l2: 1.36755\n",
      "[600]\tvalid_0's l2: 1.41346\n",
      "[700]\tvalid_0's l2: 1.36486\n",
      "[800]\tvalid_0's l2: 1.36994\n",
      "[900]\tvalid_0's l2: 1.34485\n",
      "[1000]\tvalid_0's l2: 1.33889\n",
      "[100]\tvalid_0's l2: 3.4052\n",
      "[200]\tvalid_0's l2: 2.13587\n",
      "[300]\tvalid_0's l2: 1.63624\n",
      "[400]\tvalid_0's l2: 1.43485\n",
      "[500]\tvalid_0's l2: 1.37265\n",
      "[600]\tvalid_0's l2: 1.40606\n",
      "[700]\tvalid_0's l2: 1.34415\n",
      "[800]\tvalid_0's l2: 1.34603\n",
      "[900]\tvalid_0's l2: 1.30944\n",
      "[1000]\tvalid_0's l2: 1.30931\n",
      "[100]\tvalid_0's l2: 3.20083\n",
      "[200]\tvalid_0's l2: 2.0043\n",
      "[300]\tvalid_0's l2: 1.57112\n",
      "[400]\tvalid_0's l2: 1.39321\n",
      "[500]\tvalid_0's l2: 1.3563\n",
      "[600]\tvalid_0's l2: 1.40199\n",
      "[700]\tvalid_0's l2: 1.35569\n",
      "[800]\tvalid_0's l2: 1.35716\n",
      "[900]\tvalid_0's l2: 1.33887\n",
      "[1000]\tvalid_0's l2: 1.33847\n",
      "[100]\tvalid_0's l2: 3.2239\n",
      "[200]\tvalid_0's l2: 1.99248\n",
      "[300]\tvalid_0's l2: 1.57271\n",
      "[400]\tvalid_0's l2: 1.40819\n",
      "[500]\tvalid_0's l2: 1.3598\n",
      "[600]\tvalid_0's l2: 1.40445\n",
      "[700]\tvalid_0's l2: 1.36029\n",
      "[800]\tvalid_0's l2: 1.36129\n",
      "[900]\tvalid_0's l2: 1.3336\n",
      "[1000]\tvalid_0's l2: 1.32884\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.3148\n",
      "[200]\tvalid_0's l2: 1.32605\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l2: 1.31107\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.35359\n",
      "[200]\tvalid_0's l2: 1.32053\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's l2: 1.31779\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34653\n",
      "[200]\tvalid_0's l2: 1.34904\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's l2: 1.33654\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.34371\n",
      "[200]\tvalid_0's l2: 1.3526\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l2: 1.33746\n",
      "[100]\tvalid_0's l2: 1.84553\n",
      "[200]\tvalid_0's l2: 1.4235\n",
      "[300]\tvalid_0's l2: 1.34399\n",
      "[400]\tvalid_0's l2: 1.30451\n",
      "[500]\tvalid_0's l2: 1.31448\n",
      "[600]\tvalid_0's l2: 1.33447\n",
      "[700]\tvalid_0's l2: 1.31151\n",
      "[800]\tvalid_0's l2: 1.31962\n",
      "[900]\tvalid_0's l2: 1.31809\n",
      "[1000]\tvalid_0's l2: 1.32095\n",
      "[100]\tvalid_0's l2: 1.93214\n",
      "[200]\tvalid_0's l2: 1.46742\n",
      "[300]\tvalid_0's l2: 1.34737\n",
      "[400]\tvalid_0's l2: 1.28177\n",
      "[500]\tvalid_0's l2: 1.26905\n",
      "[600]\tvalid_0's l2: 1.29063\n",
      "[700]\tvalid_0's l2: 1.28379\n",
      "[800]\tvalid_0's l2: 1.28981\n",
      "[900]\tvalid_0's l2: 1.30482\n",
      "[1000]\tvalid_0's l2: 1.2963\n",
      "[100]\tvalid_0's l2: 1.83251\n",
      "[200]\tvalid_0's l2: 1.41877\n",
      "[300]\tvalid_0's l2: 1.33363\n",
      "[400]\tvalid_0's l2: 1.29744\n",
      "[500]\tvalid_0's l2: 1.29923\n",
      "[600]\tvalid_0's l2: 1.3181\n",
      "[700]\tvalid_0's l2: 1.28962\n",
      "[800]\tvalid_0's l2: 1.29677\n",
      "[900]\tvalid_0's l2: 1.29807\n",
      "[1000]\tvalid_0's l2: 1.30856\n",
      "[100]\tvalid_0's l2: 1.82291\n",
      "[200]\tvalid_0's l2: 1.43169\n",
      "[300]\tvalid_0's l2: 1.36347\n",
      "[400]\tvalid_0's l2: 1.32182\n",
      "[500]\tvalid_0's l2: 1.33207\n",
      "[600]\tvalid_0's l2: 1.3449\n",
      "[700]\tvalid_0's l2: 1.32037\n",
      "[800]\tvalid_0's l2: 1.33315\n",
      "[900]\tvalid_0's l2: 1.32149\n",
      "[1000]\tvalid_0's l2: 1.32327\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.40447\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 1.37575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.33538\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 1.33091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.41037\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's l2: 1.39167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 1.39207\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 1.35761\n",
      "[100]\tvalid_0's l2: 1.36686\n",
      "[200]\tvalid_0's l2: 1.33058\n",
      "[300]\tvalid_0's l2: 1.34368\n",
      "[400]\tvalid_0's l2: 1.33633\n",
      "[500]\tvalid_0's l2: 1.34706\n",
      "[600]\tvalid_0's l2: 1.33534\n",
      "[700]\tvalid_0's l2: 1.33249\n",
      "[800]\tvalid_0's l2: 1.34187\n",
      "[900]\tvalid_0's l2: 1.34363\n",
      "[1000]\tvalid_0's l2: 1.33625\n",
      "[100]\tvalid_0's l2: 1.38996\n",
      "[200]\tvalid_0's l2: 1.29407\n",
      "[300]\tvalid_0's l2: 1.26492\n",
      "[400]\tvalid_0's l2: 1.26353\n",
      "[500]\tvalid_0's l2: 1.26019\n",
      "[600]\tvalid_0's l2: 1.27848\n",
      "[700]\tvalid_0's l2: 1.27535\n",
      "[800]\tvalid_0's l2: 1.27991\n",
      "[900]\tvalid_0's l2: 1.28139\n",
      "[1000]\tvalid_0's l2: 1.28744\n",
      "[100]\tvalid_0's l2: 1.41847\n",
      "[200]\tvalid_0's l2: 1.34025\n",
      "[300]\tvalid_0's l2: 1.33943\n",
      "[400]\tvalid_0's l2: 1.33802\n",
      "[500]\tvalid_0's l2: 1.34587\n",
      "[600]\tvalid_0's l2: 1.34428\n",
      "[700]\tvalid_0's l2: 1.35235\n",
      "[800]\tvalid_0's l2: 1.35616\n",
      "[900]\tvalid_0's l2: 1.36728\n",
      "[1000]\tvalid_0's l2: 1.36915\n",
      "[100]\tvalid_0's l2: 1.41503\n",
      "[200]\tvalid_0's l2: 1.33698\n",
      "[300]\tvalid_0's l2: 1.3575\n",
      "[400]\tvalid_0's l2: 1.33318\n",
      "[500]\tvalid_0's l2: 1.3294\n",
      "[600]\tvalid_0's l2: 1.32733\n",
      "[700]\tvalid_0's l2: 1.33495\n",
      "[800]\tvalid_0's l2: 1.3543\n",
      "[900]\tvalid_0's l2: 1.35982\n",
      "[1000]\tvalid_0's l2: 1.36933\n",
      "Best score: 0.00\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'boosting': 'dart', 'objective': 'regression', 'metric': 'mse', 'is_training_metric': True, 'feature_fraction': 0.9}\n"
     ]
    }
   ],
   "source": [
    "best_mse=0\n",
    "for n_estimator in [100, 300, 600]:\n",
    "    for learning_rate in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for boosting in ['gbdt','dart']:\n",
    "            for max_depth in [-1,4,6,9]:\n",
    "                params={'learning_rate': learning_rate, 'max_depth': max_depth, \n",
    "                            'boosting': boosting, 'objective': 'regression', \n",
    "                            'metric': 'mse', 'is_training_metric': True, \n",
    "                            'feature_fraction': 0.9}\n",
    "                model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)\n",
    "                y_pred = model.predict(X_test)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                \n",
    "                if mse < best_mse:\n",
    "                        best_mse = mse\n",
    "                        best_parameters = params\n",
    "                        \n",
    "print(\"Best mse: {:.2f}\".format(best_mse))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l2: 3.48129\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l2: 3.48129\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-6924cf30c08f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 90\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "best_score=0 \n",
    "for n_estimator in [100, 300, 600]:\n",
    "    for learning_rate in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for boosting in ['gbdt','dart']:\n",
    "            for max_depth in [-1,4,6,9]:\n",
    "                params={'n_estimators':n_estimator ,'learning_rate': learning_rate, 'max_depth': max_depth, \n",
    "                            'boosting': boosting, 'objective': 'regression', \n",
    "                            'metric': 'mse', 'is_training_metric': True, \n",
    "                            'feature_fraction': 0.9}\n",
    "                model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)\n",
    "                y_pred = model.predict(X_test)\n",
    "                score= accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_parameters = params\n",
    "                        \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서부터 보시면 됩니다~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgbm = LGBMRegressor(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm=LGBMRegressor(n_estimators=500, learning_rate=0.1, max_depth=4)\n",
    "lgbm.fit(X_train,y_train)\n",
    "lgbm_pred=xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9581624716310267\n",
      "0.8944153514504809\n"
     ]
    }
   ],
   "source": [
    "print(lgbm.score(X_train, y_train))\n",
    "print(lgbm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.90\n",
      "Best parameters: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.2, 'boosting': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "best_score=0\n",
    "for n_estimator in [100, 300, 600]:\n",
    "    for learning_rate in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for boosting in ['gbdt','dart']:\n",
    "            for max_depth in [-1,4,6,9]:\n",
    "                lgbm= LGBMRegressor(n_estimators=n_estimator,\n",
    "                                      learning_rate=learning_rate,           \n",
    "                                      boosting= boosting,\n",
    "                                      max_depth=max_depth)\n",
    "                lgbm.fit(X_train, y_train)\n",
    "                score=lgbm.score(X_test, y_test)\n",
    "                \n",
    "                if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_parameters = {'n_estimators':n_estimator, 'max_depth' : max_depth,\n",
    "                                            'learning_rate' : learning_rate,\n",
    "                                            'boosting':boosting}\n",
    "                    \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 23.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 26.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "lgbm_param_grid={'n_estimator': [100, 300, 600],\n",
    "                 'learning_rate' : [0.01, 0.05, 0.1, 0.2],\n",
    "                 'boosting' : ['gbdt','dart'],\n",
    "                 'max_depth' : [-1,4,6,9]\n",
    "}\n",
    "\n",
    "grid_search= GridSearchCV(lgbm, lgbm_param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result= grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
